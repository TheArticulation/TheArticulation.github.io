---
title : "The Articulation Episode 8. How To Turn Jordan Peterson Into A Smiling Nazi"
toc: true
toc_label: "My Table of Contents"
toc_icon: "bars"
---
# Link To Episode Eight
{% include video id="bmRfg_JzzFE" provider="youtube" %}
I forgot to hit capture audio when I shared the Jordan Peterson videos. To fill them in, please follow the time stamped links in the description, listen till the end of that point and return to our episode. The are ordered according to each point as it appeares in the prelude. 

What is the transcendental rational ethical structure? https://youtu.be/GEf6X-FueMo?t=4934

Peterson says the ethic in an immature form: https://youtu.be/aALsFhZKg-Q?t=2645

Peterson says that in a decoded form ethics is not motivating: https://youtu.be/aALsFhZKg-Q?t=3119


## Introduction
I don’t have the time to do as much polishing as I’d like. If you are familiar with Jordan Peterson, I integrate all of what he has been looking to say in this article and accompanying podcast. I calculate there to be deep value in the following post, as well with the podcast post. Please look past any friction to extract it for yourself. I hope my computational psychoanalysis of Peterson and Peterson as a potential nazi is entertaining. It was a fun way to frame these insights. 
## Definitions
- Realism: Something is real if one’s causal model is complex and expansive enough to include it. It is very rare that the extent that something is real is that it is constituted only by an unmapped symbol. When one makes claims about the unreality of something, they are just stating that their set of nested causal models has not yet integrated the concept in question.  

- Facts refers to ideas that are congruent and integratable with a causal model of the world. They are dependent upon the given causal model. Most people claim facts with respect to a shared low resolution causal model. 

- Rationality: the cognitive process that produces pragmatic conclusions from an expensive and granular analysis. Everything can be framed as rational or indirectly rational with a model of cognitive economics. Something only appears as irrational if you don’t have a causal model of the phenomena that is occurring. Just because something is framed as irrational does not induce a violation of causality, your model just doesn’t include a model of this causal process. In layman terms both Unreality and Irrational mean.

- Cognitive Error: sometimes this is what one is attempting to communicate when one claims irrationality, but this meaning must be distinguished for precision. A cognitive error occurs when a computational system (1) makes mistakes directly in computation. (2) Relative cognitive error occurs  when the computational heuristic employs a poor, but often cheaper, computational heuristic when the resources to learn and employ a more precise, but often more costly version. 

- Complexity Scale Analogy. The amount of computational complexity that a system can run may be represented on the scale of 1-10. A system of low complexity (say 2) can have their behavior transformed into the outputs calculated by a system of higher complexity (say 6). These behavioral transforms allow for the integration of a diversity of people, even if they are playing different games. The desire to participate in this distributed computational strategy is what Jordan Peterson has identified as his religious instinct. 

## Commonalities 
We may share this epistemic process of not believing. Peterson acts as if God exists. This functions as if he was taking into account the long term consequences of his actions. It is better then not long term optimization heuristic, but it doesn’t compare directly building models of the future and living life accounting for their constraints if the person has such capabilities.  

Optimizing for resiliency and maximum efficiency, evolving past structures and ideas is the ideal strategy. Destroying systems and rebuilding from the ground up induces fragility and a short term dip in output. Evolving systems are ideal in optimization terms and should be attempted before destructive strategies. 

The closest structure of ideas which I could evolve to math mine are those of Pragmatism. I have the name for it too! However, I draw upon and look to integrate many areas including; naturalism, analytic philosophy, psychoanalysis, anthropology, psychology, sociology, economics, religions and more. Role of conservatism, the past ideology, is to identify strategies conducive to a shared ideal and distribute both the computation and work load of their derivation and implementation. 

This is existence, where the system (agent) that is to exist is to be defined by evolution. Evolution defines systems to exist that recursively select for themselves and variants of the systems which they are dependent upon.

In response to Sam Harris, if you have a model of cognitive economics nothing is irrational. Decision making may be misapplied according to an articulated model of cognitive economic tracking and be more conservative than an articulated model would dictate. The agent in question is just running a frugality algorithm instead of an optimization algorithm based upon a precise model. 

The hero is the person who identifies more effective strategies and encodes them into the social structure and dogma. This means that the hero fulfills two roles, (1) identifying wisdom and (2) distributing it. We can formalize these both in a scientific process. This is Piaget’s aim to integrate religion and science. https://youtu.be/BQ4VSRg4e8w?t=788

## Differences 

Daniel Schmitchenburger says that there is no algorithm for wisdom, Jordan Peterson says something similar. I find that to just be wrong. 

What is the transcendental rational ethical structure? https://youtu.be/GEf6X-FueMo?t=4934

Peterson says the ethic in an immature form: https://youtu.be/aALsFhZKg-Q?t=2645

Peterson says that in a decoded form it is not motivating: https://youtu.be/aALsFhZKg-Q?t=3119

The motivation for this is pragmatic survival. If working to make it so that humanity, your society, or your future descendants isn’t motivating, then what about selfishness? Medicine is increasing at a great rate, life extension technologies that can enable individuals to approximate immortality are almost here. Why waste the resources to give someone immortality, to let them into a heaven on earth, if their behavior is incompatible with living across such a timespan anyways? Why give a community of people access to longer lives if their behaviors are so poorly calculated that it results in their death anyways? Even if society can’t offer you immortality and a place in a heaven on earth, then wouldn’t acting in a manner that brings such a state be the most courageous thing you could do when faced with your own mortality under the constraints you were dealt? Now that i’ve stated it, the opportunity cost of your behaviors is behavior that creates such a heaven on earth. If you were to avoid running the calculation, or following the heuristics provided to you by those who attempted it, then you’d actively be working to bring about not a heaven, but a hell. In the face of your mortality, you’d be acting with not ultimate courage, but ultimate vengeance. This is why the decoded form of is motivating, even more motivating than any of its encoding forms for those who can tackle its complexity. 

To accomplish Piaget’s integration, we need to convert wisdom into an optimization problem that we can research. Peterson hasn’t articulated this fully. To run any morality you must exist, to win a game or an arbitrary set of games you must exist. The transcendental ethic that exists across all ethical systems is therefore the optimization of systematic existence (where you are a complex system that can be selected for). The ordering of what the system definition to be selected for is an extension of this optimization problem. What system scope definition enables a process of recursive selection. When you expand the system size, the granularity of its constituent subsystem definitions. Note that a strategy for optimizing for a continuous duration may be approximated by selecting for shorter time intervals, enacting such locally optimized solutions and error correcting. The duration of selection used for such an approximation is the third metric. When you expand all three of these metrics the complexity of each one and the overall problem increases. The expansion of these three must be balanced according to the amount of potential energy nested within the local system. The local system is defined as the system whose scope is the largest possible, while preventing incapacitation. The ability to act upon external and internal systems is retained. Part of this potential energy is spent upon the computation of action and allocation of energy itself. Joscha Bach has this reversed, where energy is a function of computation. The advantages/ disadvantages of that perspective still need to be analyzed. 

People claim that the mind is not understood and something of large complexity. These claims are true for their subjective experience as existence denies them access to understanding what is occurring. The mind is most precisely modeled by a functionalist approach. The mind’s functionality is an attempt to solve all the problems of existence and sustain an existence of itself. If you don’t take responsibility for yourself, those around you or really any of the threats to existence, then such a model induces cognitive dissonance within you. You will find that you take responsibility for some subset of problems, even if limited to maintaining basic substance. All the emotional feedback you have are attempts to boot strap you to the point where you can problem solve a larger set of problems in a more sustainable manner. Claims that we don’t  understand the mind are nothing more than attempts to avoid the responsibility that is imposed by understanding the functionality it is attempting to execute. Claims that the mind is a mystery is an attempt to hide responsibility in the fog. 

Peterson understands the phenomenological utility of art, but not the articulated utility of art. It's utility has been articulated both by Fredrich Nietzche, Otto Rank and in part by Joscha Bach. I haven’t heard Peterson articulate it, but neither have I heard him clearly articulate the economic functionality of cognitive resources.  

The religious instinct really just seems like the employment of an engrained frugality strategy. It is only overwritten when one adopts a vision that is not obtainable given current socially distributed epistemologies or when one has a precise model of the state of their cognitive economic functionality. 

I enjoy the view on identity that resembles a solution to problems. This is derived from piaget and included in Petersons lecture on piaget. This integrates both your biological set of solutions and computational set of solutions as sub strategies. Perspectives often try to reduce complexity by dissociating one or the other. Joscha bach focuses only on the computational component to thus reduce the challenge of an immortality quest. 

Jordan is still ideological. Let me explain. In one of his podcasts, I think this recent one with his son, he is discussing writing. He says that the paper has varying levels of complexity, the word, the sentence, the paragraph, the chapter, the organization of the paper as a whole and the question/ problem/ prompt the paper is an exploration of. 

Peterson hasn’t been looking at the underlying prompt, the underlying problems… In religious terms he hasn’t taken full responsibility for the suffering and sin of the world. Therefore his view of potential thesis statements, potential solutions is confined by a narrow set. You could claim that he took the algorithm of a psychologist proposed by Yung and ran it. This algorithm about the role of a future psychologist is presented at the end of one of his more famous books, I think the archetypes one, but I haven’t touched it for over a year now. 

He has varied many of the variables within cognitive psychology, the effects of religion within the domain of social psychology. Yet he hasn’t varied variables relating to the optimization of relationships and the optimization of economics.  This limits the extent of the landscape he has potential to explore and his larger scale impact. Doing so has however allowed him to enact incremental improvement on the strategies that are stored within the sets of conservative strategies of society. I lack a model of how effectively these heuristics can be updated, encoded and distributed. He may have a model that presents a limited scope.  

He, along with the atheists still haven’t decoded everything into what they call a “transcendental rationality”. However, that's been done many times before. I see it in partial form as early as Spinoza. The generator function of this transcendental ethical system is indicated by anyone that has said “the purpose of life is to live”. This creates a language in which all behaviors and institutions can be analyzed in terms of how effectively they recursively enable life. The ultimate aim is continuity of life in some form for the rest of time. Since that is a complex problem, intermediate approximations can be made. For example, have an ethic designed to optimize for the next thousand years, iterate that and error correct. However, that isn’t the ultimate transcendental ethic, but just an approximation. As the models of the future improve in granularity, so should the scope of the approximations. So a more transcendental ethical system is one that can account for the next two thousand years, iterate that, and correct. The ultimate transcendental ethic is the one that solves the problems of survival for an infinite/ continuous time frame. 

The scope of the systems that this ethic it selects for is defined by its initial conditions and by what is running this recursive selection process most effectively. If a system refuses to adapt, expand the domain of problems and environments it can resolve, then the ethic can look to integrate such systems at the cost of resources, or let it fade across time and select for a more easily integratable variant. The distribution of system size and projected iteration scope should ultimately be chosen by what is most recursive given the constraints/ initial conditions. Distributed computational strategies can make recursive survival appropriate for larger pluralistic systems for longer projected durations, where requiring direct computation wouldn’t.   

Peterson does two really cool things, first he tells people to take maximum responsibility, this functions to enable them to mature and play the most precise game possible given their constraints. I think if coupled with a model of cognitive economics, as I will cover next, then this is the algorithm one runs to reach their potential. The other thing is that it enables one to derive a toolkit to lead conservatives. He has been identified as a conservative leader too, showing his toolkit works. The disappointing part is he isn’t a visionary, he has nowhere to lead us. 

He continuously says, "Render unto Caesar the things that are Caesar's, and unto God the things that are God's" and use that to abdicate responsibility. He is not a fool, so he takes the intimidating challenges and hides them in the fog. He gives this fog’s name “God”. Note he rightly takes the Jungian insight that the socialist societies of the twentieth century tried to take the identity of a religion, of “God”, but failed to effectively take the accompanying responsibility. 


## How to Turn Jordan Peterson into a Smiling Nazi

Disclaimer, this is not a guide to make nazi’s, but an articulation as to how they are generated. Reading this information means you could go start a cult, but that would be an avoidance strategy of your larger responsibilities needed to live. The opportunity cost would be the adoption of your existential responsibility to ensure that there will be an existence of complex systems in the future. Instead please read what follows as a means of future proofing future yourself and future generations from becoming Nazi’s. 

Jordan Peterson’s has asserted that one of his goals in his past work has been to understand how someone could become a nazi, even how someone could even be a happy nazi. His motivation was asserted to be to figure out how he could become a nazi or even a happy nazi. 

To understand how Peterson or even you could become a Nazi, we will need to build from a few different models. I don’t like the “first principles” nonsense many people rely on these days to justify their models. Instead I use the pragmatic analysis that employing these models make systems more adapted and confers to them survival value. So no “first principles”, my assumptions are justified so far as their employment will keep you alive more frequently then competing assumptions would. I will start from an assumption/ concept of causality, derive a model of evolution, derive a model of survival economics, and a model of computational economics. From computational economics we can then model the conditions in which Jordan Peterson would become a happy Nazi.

In a fully decoded manner I find that all behaviors can be causally modeled in terms of attempts to create survival value and resolve selection pressures. Evolution and evolutionary explanations are not causal models, but function heuristics that point at where causal models can be found. By claiming a function has evolved, you can then trace back the conditions and pressures that evolved said function. Looking locally at the interaction between systematic growth under evolutionary constraints is where the causality can be found. 

We can abstract this causal interaction between systems and their selection pressures to generate the fundamental concept of economy. Generically defined the economy of a system refers to the management of resources. If a system allocates resources in a manner that resolves the selection pressures imposed upon it, then it will continue existing in some manner. This is what reproduction does. If the genetics of an organism enable it to allocate its resources, physical and behavioral, in a manner where it both survives and finds a mate, then the genetic design of the organism will be highly conserved across time until it dies, and partially conserved across time as long as its progeny survive and also reproduce. Organismic economic systems that allocate resources in a manner that resolves selection pressure across time will causally continue to exist, even if in indirect forms. 

To simplify this lets remove the added constraint of reproduction and look at direct survival. If you are to survive, then both your physical constitution and behaviors must allocate resources in a manner that resolves selection pressures. If your organismic economy is such that you end up trying to spend more resources than you actually have, then you’ll fail to fully execute your attempted survival strategy. In the most basic form of such economic overspending the organism would simply receive feedback that they are approaching or in a deficit. In more extreme cases the selection pressure would not be resolved and would incapacitate or destroy the organism that failed to produce the necessary output. 

Look at the opposite extreme of economic design, an organism could allocate its resources so that it resolves an immediate selection  pressure, but wastes the rest of its resources. While the organism would have still survived, it will be poorer off due to opportunity cost. Had it spent its resources to resolve the selection pressures it faced in a nested fashion, where its allocation resolves current and future selection pressures, then it would have. For future states of the organism it will have more resources to allocate for the selection pressures it is faced with, as many of them have already been accounted for with the investment of past resources. 

An organism optimized for survival will allocate the full amount of resources at its disposal. It does not overspend to the point where it is incapaicated or killed. It does not underspend as it would be less efficient by opportunity cost. If this organism is forced to compete, then the competing organism that is more efficient, but doesn’t overspend will outcompete the underspending organism across time.  

Looking at the evolution of a group of organisms, if the organism does not have a model of their resources, either articulated or encoded, then the most effective survival and reproductive strategy is to be consevative. The organism needs to spend the bare minimum amount of resources needed to survive and reproduce under the constraints of competition. If the organism does not implement a consetvative economic allocation strategy, and end up overspending then fail all together. Under the constraint of no model and no ability to generate a model, concervitive allocation of resources and thus conservative behaviors is the only viable strategy. 

Since our genetics are relatively static from birth compared to our behaviors, we can further simplify our full model of an organismic survival economy to a computational based organismic survival economy. In other words if the organism computes and executes the behaviors needed to resolve selection pressures given its genetic constraints, then it will continue existing. The same model of economy applies here, but may be explained in computational terms and cognitive resources. An organism without a model of its resources optimized strategy is one of conservatism. 

This gets us into epistemology, a branch of philosophy, let’s refer to it as economic epistemology. One can conserve their cognitive economic resources through a diversity of means. First we have distributed computation. This is where you avoid spending cognitive resources by deferring the majority of your decision making process to those around you. Political ideologies are an example of this, as well as socially derived identities. Instead of deriving ideas and behaviors yourself, allow your society to derive them, encode them, and communicate them to you. You can then spend your effort acting out the strategies that have been encoded for you. 

For an example of identity, say I want to solve the medical issues of my community. I could research a landscape of potential solutions and find becoming a philosopher/ psychologist is actually the most optimal thing for me to do given all my constraints. That would take a bunch of time and computation, I could also solve this problem by deriving the generic solution provided by the society. I’d then look to become a doctor and try to do well at college to go to med school. I may often find myself experiencing something like imposter syndrome, because I have locally executed the computation that sets becoming a doctor as an ideal strategy to accomplish my goal. I just deferred to society. Alas, that would be the best I could do since I didn’t have an economic model of my cognitive resources.

This strategy of consetvative economics is reflected in the amygdala of your brain. When under certain environmental constraints, you may experience anxiety and then defer to emotional based processing to generate a cheap, but short term oriented solution. Think of fight or flight as the most extreme example of this. We can now begin to turn Jordan Peterson into a nazi.

We need to design a set of goals, a game, for Peterson to play. We then need to have the optimized conservitive strategy be to adopt the identity of being a nazi. We can then prescribe all sorts of behaviors to the identity of being a nazi party memeber. The most extreme and effective example is to impose the game of short term survival upon him. By doing so, we will prevent him from ever having the resources to play a more complex game. Doing so will also make the deferral of his behavior to his group identity the optimized strategy. As long as this identity provides the perception that he will win at the game he is playing, he will be a happy member of the group. Jordan peterson will be a smiling Nazi. 

As far as I can see, there are two mediocre methods of making deferral to group identity, not the optimal strategy for life. Then there is also one supreme method. First is to stumble upon a model of your computational and organismic resources. Using this model, continuously out perform those around you and invest those resources in becoming more effective. Then spend excess resources to derive a strategy that is more effective than deferral to group identity, like fleeing to America. When you have one, you can stop pretending to be a smiling nazi and go execute the strategy of your own design. 

The second method is to stop playing the short term survival game. If you get into Eastern philosophy, they'll tell you to not play any game and dissociate from all sources of feedback. Achieve nirvana by taking no responsibility. If you want to spend your life asleep, then the Buddha is your man. This changes what an optimal strategy would be and denies nazism.

The third and best method is to integrate the short term survival game into a game of larger scope. This also changes what an optimal strategy would be and denies nazism. This assumes that you have the computational resources available to perform such calculations without being selected against. It is a great strategy to model out the resources of your organism and cognition to manage them economically. Unless you're lucky enough to be born with one, then you’ll have to play out the archetype of the fool. You’ll have to build an accurate model of your resources and the scope of the game you can play with it. If you overspend, then you risk incapacitation or death. In other words, would you prefer shooting for a long life where you reach your optimized potential, but risk living no life at all? Would you prefer living a life where you have the security of living with the predictable strategies used by those around you, knowing that you’ll give up your potential and be limited by what your society can reward you as incentive?

While my ideas may have much functional similarity with Christianity, I would prefer not to give my life to communicate that there is a more noble game we can play. I don’t even have to communicate that, I just have to map the games that are currently played to games of larger sustainability and scope. I also don’t find a heaven after death to be the noblest aim. It comes at the direct opportunity cost of pursuing a heaven here in life and on earth. Heaven after life is actually a less complex game and does function as a potential intermediate game to be played when resources are not available. We as humanity have played this game and gained the benefits of more resources. I suggest we now play the game of heaven on earth and map the output of our other games to that one. 
 
You’d then be playing the largest game that is viable to you given your constraints. 

## Conclusions
Let’s encode the derivation of a transcendental ethic as a science. First we calculate the optimized strategy in a decoded manner. We instantiate this “optimized solution” in science so that it may update in a decoded manner across time. Second we pass these strategies through an encoder that sets them to run. Third, we set up feedback systems that take feedback and decode it for the scientists to then update. Communicate to everyone to know that their behavior is being mapped to solving this nested system survival problems. 
