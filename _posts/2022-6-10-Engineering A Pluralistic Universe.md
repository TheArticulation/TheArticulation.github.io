---
title : "Engineering A Pluralistic Universe (Paper)"
toc: true
toc_label: "My Table of Contents"
toc_icon: "bars"
---
A paper written for an epistemology class, where I explore the deeper meaning of both objectivity and subjectivity useing a computational model of mind.

In this paper I would like to explore a strategy of modeling and optimizing the function of epistemic systems. I will start with local epistemic systems consisting of the mind of the individual along with the heuristics one uses. Then I will expand my analysis to encompass larger scale systems, using economics and the aggregation of preferences as the focus of this paper. This exploration seeks to serve as a prolegomena to any future designs of central planning.
Von Hayek says “if we (1) possess all the relevant information, if we can (2) start out from a given system of preferences and if we can (3)) command complete knowledge of any available means, the problem which remains is purely one of logic.” If we don’t possess the knowledge of the underlying dynamics of economic design, then similar to the process of engineering proteins in synthetic biology the ideal strategy is one of direct evolution. Hayek is correct to identify the utility in deferring to market regulated price systems under such ignorance.

I believe that we are no longer operating under such ignorances and under a computational resource deficit. Both (1) the relevant information and (3)  knowledge of the means of production have clear potential to be tracked through large scale computer networks. Building models and collecting data on humanities production capacities is not that big of an ask given modern technologies. The only challenge that is left are claims of data regarding preferences being inaccessible. 
	
To derive the models of preferences I ask one to employ, one could start from the pragmatic school of thought. However, on its own pragmatism isn’t precise enough to get you very far. The pragmatic definition of truth holds that a proposition is true if it is useful to believe. The pragmatism I employ takes the relativism further and defines useful to mean the conferment of survival value. I further alter pragmatism to be relative to a given system or set of nested systems that are to exist across a stated temporal domain. Therefore the definition of truth that I use is approximately a preposition is true for a given system if it confers survival value upon that given system. 
Now to derive the implications of this for the epistemic model of the individual. My use of the term “survival value” is what Thomas Nagel has correctly identified to be the indicator of an evolutionary based epistemology. The pragmatism I employ extends into an evolutionary psychology model of the mind. Peter Carruthers’ 2006 book the Architecture of the Mind presents an in depth defense for representing the mind through a model of massive modularity. He defends evolutionary psychology as a valued heuristic that streamlines the process of defining causally related modular structures. The version of pragmatism I employ is precisely the identification of modular structures and their attempts to confer survival value upon a system. 

Deriving this theory of mind is the step that will enable us to understand individualized epsistmics. Carruthers argues that all desire generating modules are information based. If we take this claim as a premise to build upon then we can further claim that desires and the preferences they produce, can be predicted by emulating the cognitive modules themselves. This emulation of cognition is how I suggest we acquire information about (3) individual preferences to adhere to Hayek's requirements for a shot at successful central planning. One of the insights I view as key in building such epistemic models is indeed in Carruthers’ book, though I do not believe he gave it proper justice. I will seek to give the idea of computational frugality proper justice here as its regulation is one of the largest factors that govern the realm of epistemology and of preference prediction. 

Carruthers’ articulates the survival value of computational frugality when he says, “Given that the speed of processing is always one constraint for organisms that may need to think and act swiftly in order to survive, evolution will have led to compromises on the question of reliability. Indeed, it will favor a satisfying strategy rather than an optimal one.” From here Carruthers articulates the tradeoff between frugality and reliability found in various heuristics and cognitive processes. What goes unarticulated in this chapter of his work is that frugality need not always be the case. If one budgets their use of heuristical strategies according to the computational constraints imposed by their circumstances and goals, then the validity of their beliefs attains maximum justification. 

I claim that our epistemic processes are subject to the same impact of frugality. Elga opens her Reflections and Disagreements paper with the claim that “[t]here are experts and gurus, people to whom we should defer entirely”. Under the lens of frugality, this presents itself as a computational resource conserving strategy. Instead of going out to acquire evidence directly and analyze it one can just adopt the beliefs of others. Evaluating and optimizing the validity of such deferral heuristics is another conversation, for this paper lets evaluate how frugality regulates heuristic implementation. 

In terms of optimization, if your cognitive budget allows you cognitive resources to directly derive beliefs using high validity strategies, like the scientific method, then doing so is ideal. If it doesn’t, say in circumstances constraining time, then you should evaluate choosing a more frugal heuristic. Hoarding cognitive resources that go unspent is a sign of an under optimized epistemic process. It accumulates opportunity cost based epistemic errors that can be avoided by matching more costly, more valid heuristics with a precise budgeting of resources. When budgeting is imprecise or abdicated all together, beliefs and actions that follow from such processes also suffer the unnecessary errors and require further cognitive resources to be spent down the line. The truly optimized individual epistemic agent who, when cognitive resources are available, optimizes the heuristics they use and develops structures that correct for any error they produce. Such an agent retains the ability to think in a precise long-form manner when resources are luxurious, but also retains the ability to produce maximally valid solutions when employing heuristics when computational resources are scarce.
Unlike Carruthers, Thomas Nagel doesn’t endorse evolutionary epistemology. He slanders this application of evolution as an “intellectualist dogma”. Nagel is also justified in this reaction according to the massive modularity view of the mind. The issue with evolutionary theories of epistemology is that they illuminate how one's actions and their opportunity cost contribute towards the survival of oneself and the systems that they care about. One is then forced to maximize the validity of their epistemic processes, paying the price associated with the employment of more difficult heuristics and spending little time using the easier ones. If one does not pay this price, then they are forced to realize that their actions are indirectly selecting against themselves and the systems that they care about, even if just by opportunity cost. It imposes a computational cost through use of future blackmail. It is more frugal to deny such blackmail and employ frugal heuristics in an unregulated manner. Denying evolutionary theory denies the responsibilities that follow from it, hiding them in the fog of obscurement. Without the additional cognitive budgeting constraints, the agent loses the perceptual need to budget the use of complex heuristics and is thus performing a frugality based survival strategy. 

Within a modularity view of the mind accepting or rejecting evolutionary epistemology itself is pragmatically justified in either direction. Its justification is dependent on the budgeting module that manages one’s cognitive resources. What evidence does one use to evaluate their time and budget their resources? Is this function deferred to the amygdala and regulated using anxiety responses? Does one instead take model based responsibility for precisely budgeting their time and focus given their perceived externalized constraints? Understanding if the frugality-validity trade off of an epistemic process is pragmatically justified is the first step that needs to be taken if its results are to be justified overall. 

I claim Nagel’s rejection of evolutionary theorizing is the employment of a frugality survival strategy. I also claim that articulating the frugality vs validity trade off in his views on objectivity and subjectivity will provide great value. He says, “(a) view or form of thought is more objective than another if it relies less on the specific of the individual’s make and position in the world, or on the character of the particular type of creature he is.” Prima facie this view makes heuristics that shoot for objectivity come at higher computational cost as they must error correct for individual biases. However, the comparative cost of a subjective view depends on what we mean when we integrate the specifics of the individual's makeup and position in the world. If view is considered subjective because it relies on unarticulated biases, then no additional articulated evidence was included in any reasoning and it would indeed be less computationally demanding than objective reasoning. What if the subjectivity isn’t unarticulated, but based upon a model of the mind like a modularity function. 

With articulated subjectivity one must first account for their unarticulated biases, similar to objectivity. However, one further modifies their view by translating it into the language of the target audience. By integrating models of effective communication into the derivation of the view itself, articulated subjectivity is capable of reaching an even larger audience than allowed by objective perspectives. Objective views by Nagel’s definition don’t require a reintegration of information concerning various individual's makeup and position in the world. Objective views are actually less computationally demanding than views of articulated subjectivity while reaching a lesser audience than views that account for multiple subjective perspectives. The point of this conclusion is that objectivity as defined by Nagel denies the integration of those who lack the capacity to understand your “objective” perspective. The consequence of this becomes clearer when we look to model and optimize group epistemology.
According to the theory of evolutionary psychology our group's shared idealized aim is to enable systematic survival. The scope of the system and the duration of time that a system is selected for is bounded by the strategies the system employs to extract survival value from its environment. Central planning designs must function to solve the problems of systematic survival first and foremost. Objectivity as the lens of which designs should be crafted will induce error as it seeks to transcend such constraints impractically. If survival constraints are not  reintroduced into objectivity, then the view from nowhere is the view that leads to a system existing nowhere. Unarticulated subjective perspectives are no better, evolutionary psychology posits that the transformations they impose are set to confer benefit to small systems. However, such views are not scalable due to the conflict of unarticulated subjective perspectives.

Articulated subjectivity offers a potential alternative. Subjective information is taken into account and functions to transform information in a manner that confers survival value to a pluralistic universe. It is instead the view from everywhere, the view that maximally enables diversity, not by transcending subjective problems, but through looking to solve them practically. Employment of a massive modularity model of mind allows for subjective processes of individuals to be emulated. The input information identified and their output information predicted, corresponding error may be corrected for so that a larger system will be selected for.  

It is easy to confer selection value upon a small system for a small duration of time. It is easy to induce such shortsighted errors upon others by regulating the heuristics available for them to use. This is an argument against centralized planning, as an individual who uses poor heuristics gets taken advantage of in an unregulated market system. Those who apply more foresight have the largest economic benefit conferred upon themselves and are selected for financially. However, those who create the illusion that using cognitively cheap error prone heuristics and manipulate that benefit for a localized benefit also get selected for. The error here is another version of unnecessary frugality. In promoting the use of error prone heuristics across our population we cap the potential of our global output. In exchange we gain the ability for smart, but shortsighted individuals to confer themselves with large amounts of localized benefit. 

It is hard to confer selection value across a large system for a larger duration of time. It is hard to induce the desire for individuals to use more precise computationally expensive heuristics. It is hard to account for the error of cheap heuristics ahead of time and design systems that error correct for them to allow for the emulation of more valid strategies at the cheaper computational cost. Why do so when cheap heuristics can so easily be exploited for immediate localized gain? The point is effective centralized planning is only accessible to those who are willing to play Darwin’s game. It is only accessible to those willing to map the cheaper heuristics to effective strategies of large scale and long term systematic selection. Those who exploit the use of cheap heuristics to confer shortsighted localized benefit do so at the cost of a pluralistic universe that is capable of standing the test of time. 

If one doesn’t design their society around wide scale, pluralistic, long-term strategies to playing Darwin’s game, then they abdicate the ability to understand what formulates the preferences of others. The massive modularity theory of mind becomes another method of manipulation for locally optimized benefits. The primary defense democratically regulated markets have is their ability to correct for obvious errors and that the perspective itself is difficult to derive without identifying the strategy proposed here to likely be much more efficient overall. 

Understanding the preferences of a system's constituent agents is a complex task. Polling and voting offer a heuristic method for doing so. In this paper I explored the claim that individual preferences could be ascertained through emulation of cognitive processes. I claimed that the only method of central planning that could compete with distributed computation is one where the central planner adopts the perspective of an evolutionary psychologist. One must understand and take responsibility for all the suffering, all the evolutionary selection pressures that others face and encode strategies of conferring survival value into their plans. One must do so for large scale diverse systems of information encoding for large temporal domains. One must decode the effect of their own subjectivity and transform their views in a manner that includes the entire system they take responsibility for. As Spinoza said in his work The Ethics, “If the way I have shown to lead to these things now seems very hard, still, it can be found. And of course, what is found so rarely must be hard. For if salvation were at hand, and could be found without great effort, how could nearly everyone neglect it? But all things excellent are as difficult as they are rare.” (Spinoza, pg. 265) Central planning is a difficult task, a diverse integrated society is worth the effort.

References
Carruthers, P. (2006). The architecture of the mind; Massive modularity and the flexibility of thought. In The architecture of the mind; Massive modularity and the flexibility of thought. Clarendon Press/Oxford University Press. https://doi.org/10.1093/acprof:oso/9780199207077.001.0001
Elga, A. (2007). Reflection and Disagreement. In NOUS (Vol. 41, Issue 3). https://about.jstor.org/terms
Hayek, F. A. (1945). The Use of Knowledge in Society. In The American Economic Review (Vol. 35, Issue 4).
Nagel, T. (1986). The view from nowhere. Oxford University Press.
Rawls, J. (1997). The Idea of Public Reason.

